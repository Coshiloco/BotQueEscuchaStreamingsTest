Using device: cuda
D:\AnacondaImportante\envs\whisper\Lib\site-packages\torch\_utils.py:89: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\cb\pytorch_1000000000000\work\c10/cuda/CUDAAllocatorConfig.h:28.)
  untyped_storage = torch.UntypedStorage(self.size(), device=device)
Comando de ffmpeg configurado correctamente
Starting FFmpeg...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
Waiting for pruebavocesdosmedicionesbuena.wav to be created...
pruebavocesdosmedicionesbuena.wav has been created. Starting transcription...
Starting transcription...
Transcription complete in 4.84 seconds at minute 0.09.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer.
Starting transcription...
Transcription complete in 5.47 seconds at minute 0.24.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenLive la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo.
Starting transcription...
Transcription complete in 6.17 seconds at minute 0.34.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología
Starting transcription...
Transcription complete in 10.94 seconds at minute 0.49.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo.
Starting transcription...
Transcription complete in 14.29 seconds at minute 0.74.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wai que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando es que si te lo quieres hablar, te lo quieres hablar.
Starting transcription...
Transcription complete in 20.58 seconds at minute 0.98.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wai que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo.
Starting transcription...
Transcription complete in 27.28 seconds at minute 1.38.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wai que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien.
Starting transcription...
Transcription complete in 35.98 seconds at minute 1.88.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wai que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien. Sí, me está marcando que el micrófono no está tan alto como me gustaría, vamos a subirlo, vamos a subirlo un poquito la ganancia y ya veréis chicos que bien estamos. Mucho mejor ahora, ahora deberíais de escucharme con un poquito más de nitidez. Bueno, lo que comentaba, modelos de generación de vídeo. Introducing Gen3 Alpha, recordemos, Runway es una empresa a la que yo le tengo mucho cariño cuando visité, mira, algunos los habéis fijado en los vídeos habéis...
Starting transcription...
Transcription complete in 44.45 seconds at minute 2.53.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wai que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien. Sí, me está marcando que el micrófono no está tan alto como me gustaría, vamos a subirlo, vamos a subirlo un poquito la ganancia y ya veréis chicos que bien estamos. Mucho mejor ahora, ahora deberíais de escucharme con un poquito más de nitidez. Bueno, lo que comentaba, modelos de generación de vídeo. Introducing Gen3 Alpha, recordemos, Runway es una empresa a la que yo le tengo mucho cariño cuando visité, mira algunos los habéis fijado en los vídeos, a veces tengo en la mesa un PIN que es el logo de Runway, que me lo dieron de cuando le visité en Nueva York hace ya un par de años, no sé si fue 2021 o 2022, pero es una empresa que me gusta mucho porque la conozco incluso antes de que dieran el paso al mundo de la generación de vídeo, la conozco de cuando era simplemente un aglutinador de modelos que podías conectar entre ellos y desde entonces pues ellos han abierto una línea de trabajo muy interesante que son los modelos Gen1.
Starting transcription...
Transcription complete in 60.94 seconds at minute 3.32.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wide que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien. Sí, me está marcando que el micrófono no está tan alto como me gustaría, vamos a subirlo, vamos a subirlo un poquito la ganancia y ya veréis chicos que bien estamos. Mucho mejor ahora, ahora deberíais de escucharme con un poquito más de nitidez. Bueno, lo que comentaba, modelos de generación de vídeo. Introducing Gen3 Alpha, recordemos, Runway es una empresa a la que yo le tengo mucho cariño cuando visité, mira algunos los habéis fijado en los vídeos, a veces tengo en la mesa un pin que es el logo de Runway, que me lo dieron de cuando le visité en Nueva York hace ya un par de años, no sé si fue 2021 o 2022, pero es una empresa que me gusta mucho porque la conozco incluso antes de que dieran el paso al mundo de la generación de vídeo, la conozco de cuando era simplemente un aglutinador de modelos que podías conectar entre ellos y desde entonces pues ellos han abierto una línea de trabajo muy interesante que son los modelos Gen1, Gen1 salió si no recuerdo mal a finales de 2022, me bailan las fechas, pero era un modelo de estilización de vídeo, tú tienes un vídeo, coges una imagen, una textura y de repente pues, te puede cambiar ese vídeo aplicando una textura. Es una herramienta creativa que está guay pero tampoco era algo que a nivel profesional se pudiera utilizar y no era tampoco lo que ya se estaba empezando a ver al menos en el ámbito de la generación de imágenes. Cuando ya estaba saliendo stable diffusion ya sabemos que lo que nos molaba nosotros era crear a partir de una imagen o a partir de un prompt de texto un vídeo o una imagen o un contenido audiovisual. Eso llegó con Gen2, Gen2 es un modelo de generación de vídeo tal cual escribes un prompt, te genera un vídeo, vale hasta ahí y ahora tenemos la salida de Gen3 y amigos está bastante guapo, está bastante guapo. Quiero que veamos algunos de los resultados vamos a entrar directamente aquí para
Starting transcription...
Transcription complete in 70.84 seconds at minute 4.36.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wide que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que es bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien. Sí, me está marcando que el micrófono no está tan alto como me gustaría, vamos a subirlo, vamos a subirlo un poquito la ganancia y ya veréis chicos que bien estamos. Mucho mejor ahora, ahora deberíais de escucharme con un poquito más de nitidez. Bueno, lo que comentaba, modelos de generación de vídeo. Introducing Gen3 Alpha, recordemos, Runway es una empresa a la que yo le tengo mucho cariño cuando visité, mira algunos los habéis fijado en los vídeos, a veces tengo en la mesa un pin que es el logo de Runway, que me lo dieron de cuando le visité en Nueva York hace ya un par de años, no sé si fue 2021 o 2022, pero es una empresa que me gusta mucho porque la conozco incluso antes de que dieran el paso al mundo de la generación de vídeo, la conozco de cuando era simplemente un aglutinador de modelos que podías conectar entre ellos y desde entonces pues ellos han abierto una línea de trabajo muy interesante que son los modelos Gen1, Gen1 salió si no recuerdo mal a finales de 2022, me bailan las fechas, pero era un modelo de estilización de vídeo, tú tienes un vídeo, coges una imagen, una textura y de repente pues, te puede cambiar ese vídeo aplicando una textura. Es una herramienta creativa que está guay pero tampoco era algo que a nivel profesional se pudiera utilizar y no era tampoco lo que ya se estaba empezando a ver al menos en el ámbito de la generación de imágenes. Cuando ya estaba saliendo stable diffusion ya sabemos que lo que nos molaba nosotros era crear a partir de una imagen o a partir de un prompt de texto un vídeo o una imagen o un contenido audiovisual. Eso llegó con Gen2, Gen2 es un modelo de generación de vídeo tal cual escribes un prompt, te genera un vídeo, vale, hasta ahí. Y ahora tenemos la salida de Gen3 y amigos está bastante guapo, está bastante guapo. Quiero que veamos algunos de los resultados, vamos a entrar directamente aquí para comentarlo en directo y quiero que me digáis, una de las cosas que quiero valorar hoy es bueno pues primero la calidad de los resultados, vamos a ver si lo situamos por encima de zoras y lo situamos por encima de Dream Machine, de Luma, luego veremos resultados, si lo situamos por encima de Kling.
Starting transcription...
Transcription complete in 91.74 seconds at minute 5.59.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wide que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que es bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien. Sí, me está marcando que el micrófono no está tan alto como me gustaría, vamos a subirlo, vamos a subirlo un poquito la ganancia y ya veréis chicos que bien estamos. Mucho mejor ahora, ahora deberíais de escucharme con un poquito más de nitidez. Bueno, lo que comentaba, modelos de generación de vídeo. Introducing Gen3 Alpha, recordemos, Runway es una empresa a la que yo le tengo mucho cariño cuando visité, mira algunos los habéis fijado en los vídeos, a veces tengo en la mesa un pin que es el logo de Runway, que me lo dieron de cuando le visité en Nueva York hace ya un par de años, no sé si fue 2021 o 2022, pero es una empresa que me gusta mucho porque la conozco incluso antes de que dieran el paso al mundo de la generación de vídeo, la conozco de cuando era simplemente un aglutinador de modelos que podías conectar entre ellos y desde entonces pues ellos han abierto una línea de trabajo muy interesante que son los modelos Gen1, Gen1 salió si no recuerdo mal a finales de 2022, me bailan las fechas, pero era un modelo de estilización de vídeo, tú tienes un vídeo, coges una imagen, una textura y de repente pues, te puede cambiar ese vídeo aplicando una textura. Es una herramienta creativa que está guay pero tampoco era algo que a nivel profesional se pudiera utilizar y no era tampoco lo que ya se estaba empezando a ver al menos en el ámbito de la generación de imágenes. Cuando ya estaba saliendo stable diffusion ya sabemos que lo que nos molaba nosotros era crear a partir de una imagen o a partir de un prompt de texto un vídeo o una imagen o un contenido audiovisual. Eso llegó con Gen2, Gen2 es un modelo de generación de vídeo tal cual escribes un prompt, te genera un vídeo, vale, hasta ahí. Y ahora tenemos la salida de Gen3 y amigos está bastante guapo, está bastante guapo. Quiero que veamos algunos de los resultados, vamos a entrar directamente aquí para comentarlo en directo y quiero que me digáis, una de las cosas que quiero valorar hoy es bueno pues primero la calidad de los resultados, vamos a ver si lo situamos por encima de zoras y lo situamos por encima de Dream Machine, de Luma, luego veremos resultados, si lo situamos por encima de Kling. En este caso, fijaos que el prompt que nos pone nos marca prompt, los reflejos sutiles de una mujer en la ventana de un tren que se está moviendo a hipervelocidad por una ciudad japonesa, vale. Y entonces Gen3, el modelo de generación de vídeo, pues nos ha generado un vídeo como este. A simple vista, la calidad de lo que estamos viendo aquí creo que no tiene la nitidez, bueno no lo creo, o sea lo sé, no tiene la nitidez que tiene por ejemplo zora pero es bastante impresionante, es bastante impresionante porque creo que es de los modelos que más se las acerca en calidad. Y ahora, vamos a ver si lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es
Starting transcription...
Transcription complete in 120.12 seconds at minute 7.18.
Transcription:  de antes o de después. Pero que no llega, no llega, no termina de aparecer, no sabemos qué pasa con esa tecnología, si OpenAI la va a abrir en algún momento al público, pero ya marca, establece, pues un cambio de rumbo de lo que puede ser una tecnología de generación de vídeos. De repente OpenAI demuestra lo que la tecnología podría llegar a hacer y eso ya es un incentivo brutal para que otros competidores en este área, porque además OpenAI ni siquiera es una empresa de generación de vídeo, pero otros competidores como Runway, como Luma que recientemente se han sumado u otros competidores como en China, la empresa K-Wide que presentó su modelo Kling, pues hayan dado su paso, hayan dado su paso y nos hayan traído tecnologías que son impresionantes. De esto te lo que quiero estar hablando hoy, pero nos vamos a centrar primero en lo que es la noticia, en la actualidad, en el modelo Gen3, quiero que veamos algunos de los resultados que hay para que vayáis entendiendo por dónde va el State of the Art, el punto más avanzado, el estado del arte de los modelos de generación de vídeo accesibles para el público y que quiero hablar un poco de todo lo que está pasando, que no es poco y que creo que es bastante interesante. Me decís que eso lleva muy bajo el volumen, vamos a subirlo un poco y lo escucharéis mejor. Vale, vale, vale, dejarme un momento, configuramos aquí rápido esto y ahora sí vamos a arrancar bien. Sí, me está marcando que el micrófono no está tan alto como me gustaría, vamos a subirlo, vamos a subirlo un poquito la ganancia y ya veréis chicos que bien estamos. Mucho mejor ahora, ahora deberíais de escucharme con un poquito más de nitidez. Bueno, lo que comentaba, modelos de generación de vídeo. Introducing Gen3 Alpha, recordemos, Runway es una empresa a la que yo le tengo mucho cariño cuando visité, mira algunos los habéis fijado en los vídeos, a veces tengo en la mesa un pin que es el logo de Runway, que me lo dieron de cuando le visité en Nueva York hace ya un par de años, no sé si fue 2021 o 2022, pero es una empresa que me gusta mucho porque la conozco incluso antes de que dieran el paso al mundo de la generación de vídeo, la conozco de cuando era simplemente un aglutinador de modelos que podías conectar entre ellos y desde entonces pues ellos han abierto una línea de trabajo muy interesante que son los modelos Gen1, Gen1 salió si no recuerdo mal a finales de 2022, me bailan las fechas, pero era un modelo de estilización de vídeo, tú tienes un vídeo, coges una imagen, una textura y de repente pues, te puede cambiar ese vídeo aplicando una textura. Es una herramienta creativa que está guay pero tampoco era algo que a nivel profesional se pudiera utilizar y no era tampoco lo que ya se estaba empezando a ver al menos en el ámbito de la generación de imágenes. Cuando ya estaba saliendo stable diffusion ya sabemos que lo que nos molaba nosotros era crear a partir de una imagen o a partir de un prompt de texto un vídeo o una imagen o un contenido audiovisual. Eso llegó con Gen2, Gen2 es un modelo de generación de vídeo tal cual escribes un prompt, te genera un vídeo, vale, hasta ahí. Y ahora tenemos la salida de Gen3 y amigos está bastante guapo, está bastante guapo. Quiero que veamos algunos de los resultados, vamos a entrar directamente aquí para comentarlo en directo y quiero que me digáis, una de las cosas que quiero valorar hoy es bueno pues primero la calidad de los resultados, vamos a ver si lo situamos por encima de zoras y lo situamos por encima de Dream Machine, de Luma, luego veremos resultados, si lo situamos por encima de Kling. En este caso, fijaos que el prompt que nos pone nos marca prompt, los reflejos sutiles de una mujer en la ventana de un tren que se está moviendo a hipervelocidad por una ciudad japonesa, vale. Y entonces Gen3, el modelo de generación de vídeo, pues nos ha generado un vídeo como este. A simple vista, la calidad de lo que estamos viendo aquí creo que no tiene la nitidez, bueno no lo creo, o sea lo sé, no tiene la nitidez que tiene por ejemplo zora pero es bastante impresionante, es bastante impresionante porque creo que es de los modelos que más se las acerca en calidad. Y ahora, vamos a ver si lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver es lo que vamos a ver, lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es lo que vamos a ver es
Starting transcription...
FFmpeg has stopped.
